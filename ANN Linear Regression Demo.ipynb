{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 963 entries, 0 to 962\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   age     963 non-null    int64\n",
      " 1   gender  963 non-null    int64\n",
      " 2   miles   963 non-null    int64\n",
      " 3   debt    963 non-null    int64\n",
      " 4   income  963 non-null    int64\n",
      " 5   sales   963 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 45.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('sales',axis=1)\n",
    "y=df['sales']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.20,random_state=1007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((770, 5), (770,), (193, 5), (193,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape,ytrain.shape,xtest.shape,ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "922    29560\n",
       "404     5040\n",
       "734    28842\n",
       "504    10401\n",
       "394     2832\n",
       "105    19634\n",
       "231      650\n",
       "618    12256\n",
       "698    17176\n",
       "320     1376\n",
       "Name: sales, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=np.asarray(ytrain)\n",
    "ytest=np.asarray(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29560,  5040, 28842, 10401,  2832, 19634,   650, 12256, 17176,\n",
       "        1376])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xtrain),type(ytrain),type(xtest),type(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(770, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 12)                72        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 185\n",
      "Trainable params: 185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 616 samples, validate on 154 samples\n",
      "Epoch 1/250\n",
      "616/616 [==============================] - 0s 122us/step - loss: 37290860.9221 - mse: 37290860.0000 - val_loss: 33664233.3766 - val_mse: 33664232.0000\n",
      "Epoch 2/250\n",
      "616/616 [==============================] - 0s 222us/step - loss: 37193441.5065 - mse: 37193440.0000 - val_loss: 33571278.4675 - val_mse: 33571280.0000\n",
      "Epoch 3/250\n",
      "616/616 [==============================] - 0s 82us/step - loss: 37095438.7208 - mse: 37095436.0000 - val_loss: 33476499.7403 - val_mse: 33476498.0000\n",
      "Epoch 4/250\n",
      "616/616 [==============================] - 0s 113us/step - loss: 37001639.2987 - mse: 37001640.0000 - val_loss: 33378816.4416 - val_mse: 33378816.0000\n",
      "Epoch 5/250\n",
      "616/616 [==============================] - 0s 272us/step - loss: 36902265.2532 - mse: 36902268.0000 - val_loss: 33276541.6364 - val_mse: 33276542.0000\n",
      "Epoch 6/250\n",
      "616/616 [==============================] - 0s 93us/step - loss: 36807652.5844 - mse: 36807648.0000 - val_loss: 33176234.8052 - val_mse: 33176236.0000\n",
      "Epoch 7/250\n",
      "616/616 [==============================] - 0s 125us/step - loss: 36715999.9935 - mse: 36716004.0000 - val_loss: 33075396.4935 - val_mse: 33075396.0000\n",
      "Epoch 8/250\n",
      "616/616 [==============================] - 0s 103us/step - loss: 36615842.4026 - mse: 36615848.0000 - val_loss: 32983010.9351 - val_mse: 32983010.0000\n",
      "Epoch 9/250\n",
      "616/616 [==============================] - 0s 91us/step - loss: 36516488.2143 - mse: 36516488.0000 - val_loss: 32890232.9091 - val_mse: 32890236.0000\n",
      "Epoch 10/250\n",
      "616/616 [==============================] - 0s 134us/step - loss: 36420495.7857 - mse: 36420496.0000 - val_loss: 32792634.4416 - val_mse: 32792636.0000\n",
      "Epoch 11/250\n",
      "616/616 [==============================] - 0s 82us/step - loss: 36326285.7857 - mse: 36326288.0000 - val_loss: 32692957.2208 - val_mse: 32692956.0000\n",
      "Epoch 12/250\n",
      "616/616 [==============================] - 0s 103us/step - loss: 36232037.9805 - mse: 36232040.0000 - val_loss: 32595660.7532 - val_mse: 32595658.0000\n",
      "Epoch 13/250\n",
      "616/616 [==============================] - 0s 91us/step - loss: 36137173.1558 - mse: 36137176.0000 - val_loss: 32500854.5974 - val_mse: 32500856.0000\n",
      "Epoch 14/250\n",
      "616/616 [==============================] - 0s 135us/step - loss: 36044044.1558 - mse: 36044040.0000 - val_loss: 32407954.5714 - val_mse: 32407958.0000\n",
      "Epoch 15/250\n",
      "616/616 [==============================] - 0s 124us/step - loss: 35945596.5260 - mse: 35945600.0000 - val_loss: 32310518.0779 - val_mse: 32310518.0000\n",
      "Epoch 16/250\n",
      "616/616 [==============================] - 0s 116us/step - loss: 35852446.2727 - mse: 35852448.0000 - val_loss: 32209389.2727 - val_mse: 32209388.0000\n",
      "Epoch 17/250\n",
      "616/616 [==============================] - 0s 98us/step - loss: 35755551.0260 - mse: 35755548.0000 - val_loss: 32111832.0519 - val_mse: 32111828.0000\n",
      "Epoch 18/250\n",
      "616/616 [==============================] - 0s 110us/step - loss: 35658238.5000 - mse: 35658244.0000 - val_loss: 32014788.9610 - val_mse: 32014788.0000\n",
      "Epoch 19/250\n",
      "616/616 [==============================] - 0s 83us/step - loss: 35562272.6039 - mse: 35562268.0000 - val_loss: 31920388.9610 - val_mse: 31920390.0000\n",
      "Epoch 20/250\n",
      "616/616 [==============================] - 0s 96us/step - loss: 35464773.2013 - mse: 35464772.0000 - val_loss: 31828142.3896 - val_mse: 31828144.0000\n",
      "Epoch 21/250\n",
      "616/616 [==============================] - 0s 82us/step - loss: 35370463.9870 - mse: 35370468.0000 - val_loss: 31734221.0390 - val_mse: 31734218.0000\n",
      "Epoch 22/250\n",
      "616/616 [==============================] - 0s 91us/step - loss: 35274871.7792 - mse: 35274872.0000 - val_loss: 31641453.7662 - val_mse: 31641454.0000\n",
      "Epoch 23/250\n",
      "616/616 [==============================] - 0s 77us/step - loss: 35177392.5519 - mse: 35177392.0000 - val_loss: 31540509.4545 - val_mse: 31540506.0000\n",
      "Epoch 24/250\n",
      "616/616 [==============================] - 0s 160us/step - loss: 35082359.1169 - mse: 35082356.0000 - val_loss: 31442131.1169 - val_mse: 31442132.0000\n",
      "Epoch 25/250\n",
      "616/616 [==============================] - 0s 201us/step - loss: 34989945.0455 - mse: 34989948.0000 - val_loss: 31342134.8571 - val_mse: 31342134.0000\n",
      "Epoch 26/250\n",
      "616/616 [==============================] - 0s 78us/step - loss: 34892378.2338 - mse: 34892376.0000 - val_loss: 31248786.4675 - val_mse: 31248786.0000\n",
      "Epoch 27/250\n",
      "616/616 [==============================] - 0s 75us/step - loss: 34799737.2597 - mse: 34799740.0000 - val_loss: 31155127.6104 - val_mse: 31155126.0000\n",
      "Epoch 28/250\n",
      "616/616 [==============================] - 0s 77us/step - loss: 34701052.9935 - mse: 34701056.0000 - val_loss: 31061236.1818 - val_mse: 31061238.0000\n",
      "Epoch 29/250\n",
      "616/616 [==============================] - 0s 190us/step - loss: 34611524.7727 - mse: 34611524.0000 - val_loss: 30956975.7662 - val_mse: 30956976.0000\n",
      "Epoch 30/250\n",
      "616/616 [==============================] - 0s 172us/step - loss: 34512216.9156 - mse: 34512216.0000 - val_loss: 30861902.6753 - val_mse: 30861900.0000\n",
      "Epoch 31/250\n",
      "616/616 [==============================] - 0s 80us/step - loss: 34417146.7597 - mse: 34417144.0000 - val_loss: 30766222.2078 - val_mse: 30766222.0000\n",
      "Epoch 32/250\n",
      "616/616 [==============================] - 0s 79us/step - loss: 34319643.7208 - mse: 34319644.0000 - val_loss: 30671487.5584 - val_mse: 30671486.0000\n",
      "Epoch 33/250\n",
      "616/616 [==============================] - 0s 95us/step - loss: 34227312.0000 - mse: 34227312.0000 - val_loss: 30569731.9221 - val_mse: 30569732.0000\n",
      "Epoch 34/250\n",
      "616/616 [==============================] - 0s 87us/step - loss: 34130724.2338 - mse: 34130724.0000 - val_loss: 30477346.3896 - val_mse: 30477348.0000\n",
      "Epoch 35/250\n",
      "616/616 [==============================] - 0s 85us/step - loss: 34033273.5000 - mse: 34033276.0000 - val_loss: 30381111.5325 - val_mse: 30381112.0000\n",
      "Epoch 36/250\n",
      "616/616 [==============================] - 0s 104us/step - loss: 33941270.6299 - mse: 33941272.0000 - val_loss: 30286657.0390 - val_mse: 30286658.0000\n",
      "Epoch 37/250\n",
      "616/616 [==============================] - 0s 93us/step - loss: 33847151.3831 - mse: 33847148.0000 - val_loss: 30188510.5714 - val_mse: 30188510.0000\n",
      "Epoch 38/250\n",
      "616/616 [==============================] - 0s 92us/step - loss: 33751390.1364 - mse: 33751388.0000 - val_loss: 30093114.2857 - val_mse: 30093112.0000\n",
      "Epoch 39/250\n",
      "616/616 [==============================] - 0s 102us/step - loss: 33652676.2273 - mse: 33652676.0000 - val_loss: 29996654.9870 - val_mse: 29996654.0000\n",
      "Epoch 40/250\n",
      "616/616 [==============================] - 0s 93us/step - loss: 33560366.2078 - mse: 33560364.0000 - val_loss: 29900580.0519 - val_mse: 29900578.0000\n",
      "Epoch 41/250\n",
      "616/616 [==============================] - 0s 159us/step - loss: 33462180.3312 - mse: 33462182.0000 - val_loss: 29805857.9481 - val_mse: 29805858.0000\n",
      "Epoch 42/250\n",
      "616/616 [==============================] - 0s 135us/step - loss: 33368274.6234 - mse: 33368274.0000 - val_loss: 29714177.8442 - val_mse: 29714180.0000\n",
      "Epoch 43/250\n",
      "616/616 [==============================] - 0s 104us/step - loss: 33276351.9481 - mse: 33276350.0000 - val_loss: 29621922.0519 - val_mse: 29621922.0000\n",
      "Epoch 44/250\n",
      "616/616 [==============================] - 0s 73us/step - loss: 33179947.7143 - mse: 33179948.0000 - val_loss: 29528166.7013 - val_mse: 29528168.0000\n",
      "Epoch 45/250\n",
      "616/616 [==============================] - 0s 99us/step - loss: 33083763.9091 - mse: 33083762.0000 - val_loss: 29432299.5844 - val_mse: 29432300.0000\n",
      "Epoch 46/250\n",
      "616/616 [==============================] - 0s 98us/step - loss: 32987745.3442 - mse: 32987744.0000 - val_loss: 29336953.7403 - val_mse: 29336956.0000\n",
      "Epoch 47/250\n",
      "616/616 [==============================] - 0s 100us/step - loss: 32894046.5714 - mse: 32894046.0000 - val_loss: 29233924.0779 - val_mse: 29233924.0000\n",
      "Epoch 48/250\n",
      "616/616 [==============================] - 0s 109us/step - loss: 32797198.3896 - mse: 32797198.0000 - val_loss: 29138501.5584 - val_mse: 29138502.0000\n",
      "Epoch 49/250\n",
      "616/616 [==============================] - 0s 77us/step - loss: 32705730.0909 - mse: 32705728.0000 - val_loss: 29046016.7532 - val_mse: 29046016.0000\n",
      "Epoch 50/250\n",
      "616/616 [==============================] - 0s 78us/step - loss: 32611761.1623 - mse: 32611760.0000 - val_loss: 28946205.6623 - val_mse: 28946202.0000\n",
      "Epoch 51/250\n",
      "616/616 [==============================] - 0s 92us/step - loss: 32514939.6948 - mse: 32514936.0000 - val_loss: 28853224.7532 - val_mse: 28853222.0000\n",
      "Epoch 52/250\n",
      "616/616 [==============================] - 0s 86us/step - loss: 32418983.0714 - mse: 32418982.0000 - val_loss: 28764158.0519 - val_mse: 28764160.0000\n",
      "Epoch 53/250\n",
      "616/616 [==============================] - 0s 84us/step - loss: 32327091.5065 - mse: 32327092.0000 - val_loss: 28667639.3506 - val_mse: 28667638.0000\n",
      "Epoch 54/250\n",
      "616/616 [==============================] - 0s 75us/step - loss: 32231809.4675 - mse: 32231806.0000 - val_loss: 28580294.2338 - val_mse: 28580296.0000\n",
      "Epoch 55/250\n",
      "616/616 [==============================] - 0s 70us/step - loss: 32138878.7078 - mse: 32138878.0000 - val_loss: 28486542.0779 - val_mse: 28486542.0000\n",
      "Epoch 56/250\n",
      "616/616 [==============================] - 0s 81us/step - loss: 32044504.9545 - mse: 32044504.0000 - val_loss: 28394652.2078 - val_mse: 28394652.0000\n",
      "Epoch 57/250\n",
      "616/616 [==============================] - 0s 86us/step - loss: 31954001.4805 - mse: 31954004.0000 - val_loss: 28302044.4935 - val_mse: 28302044.0000\n",
      "Epoch 58/250\n",
      "616/616 [==============================] - 0s 80us/step - loss: 31860468.1623 - mse: 31860466.0000 - val_loss: 28217513.5584 - val_mse: 28217514.0000\n",
      "Epoch 59/250\n",
      "616/616 [==============================] - 0s 99us/step - loss: 31774775.7662 - mse: 31774776.0000 - val_loss: 28130818.1039 - val_mse: 28130820.0000\n",
      "Epoch 60/250\n",
      "616/616 [==============================] - 0s 98us/step - loss: 31681763.0065 - mse: 31681758.0000 - val_loss: 28041097.2468 - val_mse: 28041096.0000\n",
      "Epoch 61/250\n",
      "616/616 [==============================] - 0s 73us/step - loss: 31587004.9675 - mse: 31587006.0000 - val_loss: 27949255.7403 - val_mse: 27949256.0000\n",
      "Epoch 62/250\n",
      "616/616 [==============================] - 0s 103us/step - loss: 31499183.3377 - mse: 31499184.0000 - val_loss: 27851600.5974 - val_mse: 27851602.0000\n",
      "Epoch 63/250\n",
      "616/616 [==============================] - 0s 71us/step - loss: 31402930.7532 - mse: 31402928.0000 - val_loss: 27761092.2597 - val_mse: 27761094.0000\n",
      "Epoch 64/250\n",
      "616/616 [==============================] - 0s 69us/step - loss: 31314478.1558 - mse: 31314476.0000 - val_loss: 27668044.5974 - val_mse: 27668044.0000\n",
      "Epoch 65/250\n",
      "616/616 [==============================] - 0s 108us/step - loss: 31219266.2727 - mse: 31219266.0000 - val_loss: 27577758.7532 - val_mse: 27577758.0000\n",
      "Epoch 66/250\n",
      "616/616 [==============================] - 0s 123us/step - loss: 31126301.5649 - mse: 31126302.0000 - val_loss: 27484877.7143 - val_mse: 27484880.0000\n",
      "Epoch 67/250\n",
      "616/616 [==============================] - 0s 190us/step - loss: 31035091.2922 - mse: 31035090.0000 - val_loss: 27391851.9740 - val_mse: 27391854.0000\n",
      "Epoch 68/250\n",
      "616/616 [==============================] - 0s 209us/step - loss: 30943303.6688 - mse: 30943306.0000 - val_loss: 27300710.0779 - val_mse: 27300710.0000\n",
      "Epoch 69/250\n",
      "616/616 [==============================] - 0s 105us/step - loss: 30852905.1494 - mse: 30852908.0000 - val_loss: 27205081.9481 - val_mse: 27205082.0000\n",
      "Epoch 70/250\n",
      "616/616 [==============================] - 0s 104us/step - loss: 30759097.1104 - mse: 30759094.0000 - val_loss: 27117655.5065 - val_mse: 27117656.0000\n",
      "Epoch 71/250\n",
      "616/616 [==============================] - 0s 119us/step - loss: 30667349.2532 - mse: 30667348.0000 - val_loss: 27028089.1169 - val_mse: 27028088.0000\n",
      "Epoch 72/250\n",
      "616/616 [==============================] - 0s 131us/step - loss: 30576348.1299 - mse: 30576348.0000 - val_loss: 26938205.1948 - val_mse: 26938206.0000\n",
      "Epoch 73/250\n",
      "616/616 [==============================] - 0s 92us/step - loss: 30487146.4286 - mse: 30487146.0000 - val_loss: 26849434.1558 - val_mse: 26849432.0000\n",
      "Epoch 74/250\n",
      "616/616 [==============================] - 0s 119us/step - loss: 30397841.1623 - mse: 30397842.0000 - val_loss: 26760168.1558 - val_mse: 26760168.0000\n",
      "Epoch 75/250\n",
      "616/616 [==============================] - 0s 114us/step - loss: 30305510.2403 - mse: 30305510.0000 - val_loss: 26668422.0779 - val_mse: 26668422.0000\n",
      "Epoch 76/250\n",
      "616/616 [==============================] - 0s 107us/step - loss: 30215598.0519 - mse: 30215596.0000 - val_loss: 26581426.4675 - val_mse: 26581428.0000\n",
      "Epoch 77/250\n",
      "616/616 [==============================] - 0s 67us/step - loss: 30123392.5779 - mse: 30123394.0000 - val_loss: 26485347.5325 - val_mse: 26485348.0000\n",
      "Epoch 78/250\n",
      "616/616 [==============================] - 0s 102us/step - loss: 30032665.6623 - mse: 30032664.0000 - val_loss: 26391759.2727 - val_mse: 26391760.0000\n",
      "Epoch 79/250\n",
      "616/616 [==============================] - 0s 109us/step - loss: 29941604.8701 - mse: 29941608.0000 - val_loss: 26298934.3377 - val_mse: 26298934.0000\n",
      "Epoch 80/250\n",
      "616/616 [==============================] - 0s 154us/step - loss: 29849091.4675 - mse: 29849092.0000 - val_loss: 26212466.7013 - val_mse: 26212466.0000\n",
      "Epoch 81/250\n",
      "616/616 [==============================] - 0s 81us/step - loss: 29757385.2403 - mse: 29757386.0000 - val_loss: 26125013.9740 - val_mse: 26125012.0000\n",
      "Epoch 82/250\n",
      "616/616 [==============================] - 0s 138us/step - loss: 29668500.3766 - mse: 29668502.0000 - val_loss: 26035333.7143 - val_mse: 26035332.0000\n",
      "Epoch 83/250\n",
      "616/616 [==============================] - 0s 304us/step - loss: 29576305.1429 - mse: 29576306.0000 - val_loss: 25949093.9481 - val_mse: 25949094.0000\n",
      "Epoch 84/250\n",
      "616/616 [==============================] - 0s 144us/step - loss: 29487632.0000 - mse: 29487630.0000 - val_loss: 25855287.4805 - val_mse: 25855288.0000\n",
      "Epoch 85/250\n",
      "616/616 [==============================] - 0s 90us/step - loss: 29398082.0714 - mse: 29398082.0000 - val_loss: 25762017.7662 - val_mse: 25762016.0000\n",
      "Epoch 86/250\n",
      "616/616 [==============================] - 0s 92us/step - loss: 29309324.6104 - mse: 29309324.0000 - val_loss: 25675924.2857 - val_mse: 25675922.0000\n",
      "Epoch 87/250\n",
      "616/616 [==============================] - 0s 111us/step - loss: 29221622.6818 - mse: 29221622.0000 - val_loss: 25583943.1948 - val_mse: 25583944.0000\n",
      "Epoch 88/250\n",
      "616/616 [==============================] - 0s 122us/step - loss: 29130128.7922 - mse: 29130130.0000 - val_loss: 25492632.6234 - val_mse: 25492632.0000\n",
      "Epoch 89/250\n",
      "616/616 [==============================] - 0s 80us/step - loss: 29039033.6169 - mse: 29039034.0000 - val_loss: 25402631.6104 - val_mse: 25402628.0000\n",
      "Epoch 90/250\n",
      "616/616 [==============================] - 0s 124us/step - loss: 28949703.2662 - mse: 28949704.0000 - val_loss: 25311819.7922 - val_mse: 25311818.0000\n",
      "Epoch 91/250\n",
      "616/616 [==============================] - 0s 97us/step - loss: 28861196.3766 - mse: 28861198.0000 - val_loss: 25223018.2857 - val_mse: 25223020.0000\n",
      "Epoch 92/250\n",
      "616/616 [==============================] - 0s 141us/step - loss: 28772200.2468 - mse: 28772202.0000 - val_loss: 25134373.1948 - val_mse: 25134374.0000\n",
      "Epoch 93/250\n",
      "616/616 [==============================] - 0s 122us/step - loss: 28685377.3636 - mse: 28685376.0000 - val_loss: 25050308.2338 - val_mse: 25050308.0000\n",
      "Epoch 94/250\n",
      "616/616 [==============================] - 0s 76us/step - loss: 28599714.5974 - mse: 28599714.0000 - val_loss: 24962986.1039 - val_mse: 24962986.0000\n",
      "Epoch 95/250\n",
      "616/616 [==============================] - 0s 106us/step - loss: 28509539.5065 - mse: 28509540.0000 - val_loss: 24883771.9740 - val_mse: 24883772.0000\n",
      "Epoch 96/250\n",
      "616/616 [==============================] - 0s 70us/step - loss: 28422993.0325 - mse: 28422992.0000 - val_loss: 24798402.5974 - val_mse: 24798402.0000\n",
      "Epoch 97/250\n",
      "616/616 [==============================] - 0s 108us/step - loss: 28332938.2468 - mse: 28332936.0000 - val_loss: 24706893.8182 - val_mse: 24706894.0000\n",
      "Epoch 98/250\n",
      "616/616 [==============================] - 0s 120us/step - loss: 28246833.8571 - mse: 28246834.0000 - val_loss: 24619524.0779 - val_mse: 24619524.0000\n",
      "Epoch 99/250\n",
      "616/616 [==============================] - 0s 141us/step - loss: 28156495.7727 - mse: 28156496.0000 - val_loss: 24529161.6623 - val_mse: 24529162.0000\n",
      "Epoch 100/250\n",
      "616/616 [==============================] - 0s 83us/step - loss: 28069315.3701 - mse: 28069320.0000 - val_loss: 24439246.8571 - val_mse: 24439248.0000\n",
      "Epoch 101/250\n",
      "616/616 [==============================] - 0s 106us/step - loss: 27980495.1623 - mse: 27980498.0000 - val_loss: 24349725.5584 - val_mse: 24349726.0000\n",
      "Epoch 102/250\n",
      "616/616 [==============================] - 0s 164us/step - loss: 27891249.3571 - mse: 27891250.0000 - val_loss: 24261864.5455 - val_mse: 24261864.0000\n",
      "Epoch 103/250\n",
      "616/616 [==============================] - 0s 137us/step - loss: 27804074.5325 - mse: 27804074.0000 - val_loss: 24173968.4935 - val_mse: 24173968.0000\n",
      "Epoch 104/250\n",
      "616/616 [==============================] - 0s 138us/step - loss: 27717741.9675 - mse: 27717740.0000 - val_loss: 24085456.1039 - val_mse: 24085456.0000\n",
      "Epoch 105/250\n",
      "616/616 [==============================] - 0s 166us/step - loss: 27627556.2403 - mse: 27627554.0000 - val_loss: 24004227.8961 - val_mse: 24004226.0000\n",
      "Epoch 106/250\n",
      "616/616 [==============================] - 0s 86us/step - loss: 27539289.2078 - mse: 27539290.0000 - val_loss: 23917574.1558 - val_mse: 23917574.0000\n",
      "Epoch 107/250\n",
      "616/616 [==============================] - 0s 92us/step - loss: 27451619.1623 - mse: 27451618.0000 - val_loss: 23832019.6883 - val_mse: 23832020.0000\n",
      "Epoch 108/250\n",
      "616/616 [==============================] - 0s 105us/step - loss: 27366555.3377 - mse: 27366554.0000 - val_loss: 23746508.6234 - val_mse: 23746508.0000\n",
      "Epoch 109/250\n",
      "616/616 [==============================] - 0s 85us/step - loss: 27277707.9805 - mse: 27277706.0000 - val_loss: 23665050.8831 - val_mse: 23665052.0000\n",
      "Epoch 110/250\n",
      "616/616 [==============================] - 0s 107us/step - loss: 27196704.3312 - mse: 27196706.0000 - val_loss: 23585628.7532 - val_mse: 23585630.0000\n",
      "Epoch 111/250\n",
      "616/616 [==============================] - 0s 163us/step - loss: 27106204.2662 - mse: 27106206.0000 - val_loss: 23500596.9091 - val_mse: 23500596.0000\n",
      "Epoch 112/250\n",
      "616/616 [==============================] - 0s 98us/step - loss: 27021037.2208 - mse: 27021040.0000 - val_loss: 23416884.1039 - val_mse: 23416884.0000\n",
      "Epoch 113/250\n",
      "616/616 [==============================] - 0s 134us/step - loss: 26936506.2208 - mse: 26936508.0000 - val_loss: 23333747.2987 - val_mse: 23333746.0000\n",
      "Epoch 114/250\n",
      "616/616 [==============================] - 0s 92us/step - loss: 26850966.1494 - mse: 26850966.0000 - val_loss: 23255161.7922 - val_mse: 23255164.0000\n",
      "Epoch 115/250\n",
      "616/616 [==============================] - 0s 149us/step - loss: 26768290.6948 - mse: 26768294.0000 - val_loss: 23171903.6623 - val_mse: 23171904.0000\n",
      "Epoch 116/250\n",
      "616/616 [==============================] - 0s 143us/step - loss: 26682298.6039 - mse: 26682302.0000 - val_loss: 23086941.9740 - val_mse: 23086942.0000\n",
      "Epoch 117/250\n",
      "616/616 [==============================] - 0s 107us/step - loss: 26598719.3766 - mse: 26598720.0000 - val_loss: 23007014.8052 - val_mse: 23007016.0000\n",
      "Epoch 118/250\n",
      "616/616 [==============================] - 0s 126us/step - loss: 26511314.9740 - mse: 26511314.0000 - val_loss: 22917154.0000 - val_mse: 22917154.0000\n",
      "Epoch 119/250\n",
      "616/616 [==============================] - 0s 87us/step - loss: 26425924.1299 - mse: 26425920.0000 - val_loss: 22834406.1818 - val_mse: 22834408.0000\n",
      "Epoch 120/250\n",
      "616/616 [==============================] - 0s 125us/step - loss: 26338390.8182 - mse: 26338388.0000 - val_loss: 22751741.9740 - val_mse: 22751744.0000\n",
      "Epoch 121/250\n",
      "616/616 [==============================] - 0s 97us/step - loss: 26253744.9481 - mse: 26253746.0000 - val_loss: 22668804.1039 - val_mse: 22668804.0000\n",
      "Epoch 122/250\n",
      "616/616 [==============================] - 0s 83us/step - loss: 26169986.8377 - mse: 26169988.0000 - val_loss: 22582651.7922 - val_mse: 22582652.0000\n",
      "Epoch 123/250\n",
      "616/616 [==============================] - 0s 101us/step - loss: 26083016.5390 - mse: 26083018.0000 - val_loss: 22503740.7013 - val_mse: 22503740.0000\n",
      "Epoch 124/250\n",
      "616/616 [==============================] - 0s 108us/step - loss: 25999547.6818 - mse: 25999548.0000 - val_loss: 22420720.3377 - val_mse: 22420722.0000\n",
      "Epoch 125/250\n",
      "616/616 [==============================] - 0s 84us/step - loss: 25920116.5974 - mse: 25920116.0000 - val_loss: 22333110.4935 - val_mse: 22333110.0000\n",
      "Epoch 126/250\n",
      "616/616 [==============================] - 0s 101us/step - loss: 25831037.3636 - mse: 25831036.0000 - val_loss: 22249782.5974 - val_mse: 22249782.0000\n",
      "Epoch 127/250\n",
      "616/616 [==============================] - 0s 90us/step - loss: 25745799.9610 - mse: 25745800.0000 - val_loss: 22170339.9481 - val_mse: 22170338.0000\n",
      "Epoch 128/250\n",
      "616/616 [==============================] - 0s 155us/step - loss: 25662386.6494 - mse: 25662388.0000 - val_loss: 22090226.4156 - val_mse: 22090226.0000\n",
      "Epoch 129/250\n",
      "616/616 [==============================] - 0s 192us/step - loss: 25581582.9026 - mse: 25581582.0000 - val_loss: 22009215.4286 - val_mse: 22009216.0000\n",
      "Epoch 130/250\n",
      "616/616 [==============================] - 0s 98us/step - loss: 25497796.7208 - mse: 25497798.0000 - val_loss: 21932982.2338 - val_mse: 21932982.0000\n",
      "Epoch 131/250\n",
      "616/616 [==============================] - 0s 129us/step - loss: 25415978.1169 - mse: 25415976.0000 - val_loss: 21853360.1039 - val_mse: 21853360.0000\n",
      "Epoch 132/250\n",
      "616/616 [==============================] - 0s 80us/step - loss: 25334835.6104 - mse: 25334836.0000 - val_loss: 21776412.8052 - val_mse: 21776412.0000\n",
      "Epoch 133/250\n",
      "616/616 [==============================] - 0s 64us/step - loss: 25249881.2662 - mse: 25249884.0000 - val_loss: 21695258.3117 - val_mse: 21695256.0000\n",
      "Epoch 134/250\n",
      "616/616 [==============================] - 0s 152us/step - loss: 25165618.9545 - mse: 25165620.0000 - val_loss: 21612945.2208 - val_mse: 21612946.0000\n",
      "Epoch 135/250\n",
      "616/616 [==============================] - 0s 130us/step - loss: 25087307.5162 - mse: 25087306.0000 - val_loss: 21532966.3117 - val_mse: 21532966.0000\n",
      "Epoch 136/250\n",
      "616/616 [==============================] - 0s 102us/step - loss: 25000817.3182 - mse: 25000816.0000 - val_loss: 21446903.0390 - val_mse: 21446904.0000\n",
      "Epoch 137/250\n",
      "616/616 [==============================] - 0s 159us/step - loss: 24923389.6039 - mse: 24923390.0000 - val_loss: 21367013.6104 - val_mse: 21367014.0000\n",
      "Epoch 138/250\n",
      "616/616 [==============================] - 0s 160us/step - loss: 24843752.5584 - mse: 24843754.0000 - val_loss: 21289399.8442 - val_mse: 21289400.0000\n",
      "Epoch 139/250\n",
      "616/616 [==============================] - 0s 164us/step - loss: 24763487.9935 - mse: 24763486.0000 - val_loss: 21214904.7532 - val_mse: 21214906.0000\n",
      "Epoch 140/250\n",
      "616/616 [==============================] - 0s 121us/step - loss: 24680865.1169 - mse: 24680864.0000 - val_loss: 21142623.8182 - val_mse: 21142626.0000\n",
      "Epoch 141/250\n",
      "616/616 [==============================] - 0s 80us/step - loss: 24602974.8961 - mse: 24602974.0000 - val_loss: 21065494.9610 - val_mse: 21065496.0000\n",
      "Epoch 142/250\n",
      "616/616 [==============================] - 0s 85us/step - loss: 24526422.2727 - mse: 24526420.0000 - val_loss: 20984198.9870 - val_mse: 20984200.0000\n",
      "Epoch 143/250\n",
      "616/616 [==============================] - 0s 90us/step - loss: 24442011.2273 - mse: 24442012.0000 - val_loss: 20907673.6364 - val_mse: 20907674.0000\n",
      "Epoch 144/250\n",
      "616/616 [==============================] - 0s 74us/step - loss: 24360606.4740 - mse: 24360606.0000 - val_loss: 20835343.5584 - val_mse: 20835342.0000\n",
      "Epoch 145/250\n",
      "616/616 [==============================] - 0s 90us/step - loss: 24284631.3442 - mse: 24284632.0000 - val_loss: 20758299.2727 - val_mse: 20758298.0000\n",
      "Epoch 146/250\n",
      "616/616 [==============================] - 0s 81us/step - loss: 24205420.6948 - mse: 24205424.0000 - val_loss: 20679580.0519 - val_mse: 20679578.0000\n",
      "Epoch 147/250\n",
      "616/616 [==============================] - 0s 86us/step - loss: 24123964.8052 - mse: 24123966.0000 - val_loss: 20605062.1429 - val_mse: 20605062.0000\n",
      "Epoch 148/250\n",
      "616/616 [==============================] - 0s 87us/step - loss: 24042613.4935 - mse: 24042612.0000 - val_loss: 20528899.5325 - val_mse: 20528900.0000\n",
      "Epoch 149/250\n",
      "616/616 [==============================] - 0s 75us/step - loss: 23964100.6494 - mse: 23964100.0000 - val_loss: 20456339.4026 - val_mse: 20456342.0000\n",
      "Epoch 150/250\n",
      "616/616 [==============================] - 0s 95us/step - loss: 23889206.7662 - mse: 23889206.0000 - val_loss: 20380649.4156 - val_mse: 20380650.0000\n",
      "Epoch 151/250\n",
      "616/616 [==============================] - 0s 84us/step - loss: 23809305.1883 - mse: 23809304.0000 - val_loss: 20305651.3766 - val_mse: 20305650.0000\n",
      "Epoch 152/250\n",
      "616/616 [==============================] - 0s 65us/step - loss: 23730007.3896 - mse: 23730008.0000 - val_loss: 20230885.5325 - val_mse: 20230884.0000\n",
      "Epoch 153/250\n",
      "616/616 [==============================] - 0s 62us/step - loss: 23653186.8442 - mse: 23653186.0000 - val_loss: 20156393.1169 - val_mse: 20156394.0000\n",
      "Epoch 154/250\n",
      "616/616 [==============================] - 0s 136us/step - loss: 23574797.1883 - mse: 23574798.0000 - val_loss: 20081129.9870 - val_mse: 20081130.0000\n",
      "Epoch 155/250\n",
      "616/616 [==============================] - 0s 81us/step - loss: 23497651.5325 - mse: 23497650.0000 - val_loss: 20007888.7662 - val_mse: 20007888.0000\n",
      "Epoch 156/250\n",
      "616/616 [==============================] - 0s 74us/step - loss: 23421663.6623 - mse: 23421664.0000 - val_loss: 19935346.0390 - val_mse: 19935346.0000\n",
      "Epoch 157/250\n",
      "616/616 [==============================] - 0s 113us/step - loss: 23348505.3766 - mse: 23348506.0000 - val_loss: 19858084.2727 - val_mse: 19858082.0000\n",
      "Epoch 158/250\n",
      "616/616 [==============================] - 0s 71us/step - loss: 23270221.5130 - mse: 23270220.0000 - val_loss: 19788437.3636 - val_mse: 19788438.0000\n",
      "Epoch 159/250\n",
      "616/616 [==============================] - ETA: 0s - loss: 28006994.0000 - mse: 28006994.000 - 0s 120us/step - loss: 23196653.8182 - mse: 23196654.0000 - val_loss: 19715868.4675 - val_mse: 19715868.0000\n",
      "Epoch 160/250\n",
      "616/616 [==============================] - 0s 109us/step - loss: 23120898.1753 - mse: 23120898.0000 - val_loss: 19642810.7792 - val_mse: 19642810.0000\n",
      "Epoch 161/250\n",
      "616/616 [==============================] - 0s 98us/step - loss: 23045544.7468 - mse: 23045542.0000 - val_loss: 19573028.3636 - val_mse: 19573028.0000\n",
      "Epoch 162/250\n",
      "616/616 [==============================] - 0s 72us/step - loss: 22972024.1331 - mse: 22972024.0000 - val_loss: 19500178.2987 - val_mse: 19500178.0000\n",
      "Epoch 163/250\n",
      "616/616 [==============================] - 0s 90us/step - loss: 22893940.0844 - mse: 22893938.0000 - val_loss: 19427461.5065 - val_mse: 19427460.0000\n",
      "Epoch 164/250\n",
      "616/616 [==============================] - 0s 89us/step - loss: 22817909.3182 - mse: 22817908.0000 - val_loss: 19359367.4805 - val_mse: 19359366.0000\n",
      "Epoch 165/250\n",
      "616/616 [==============================] - 0s 82us/step - loss: 22746831.8896 - mse: 22746830.0000 - val_loss: 19289079.9870 - val_mse: 19289080.0000\n",
      "Epoch 166/250\n",
      "616/616 [==============================] - 0s 75us/step - loss: 22671037.9708 - mse: 22671038.0000 - val_loss: 19223069.0779 - val_mse: 19223068.0000\n",
      "Epoch 167/250\n",
      "616/616 [==============================] - 0s 55us/step - loss: 22597102.9708 - mse: 22597106.0000 - val_loss: 19154840.9351 - val_mse: 19154840.0000\n",
      "Epoch 168/250\n",
      "616/616 [==============================] - 0s 78us/step - loss: 22524238.6883 - mse: 22524242.0000 - val_loss: 19087506.6883 - val_mse: 19087506.0000\n",
      "Epoch 169/250\n",
      "616/616 [==============================] - 0s 76us/step - loss: 22453824.7435 - mse: 22453828.0000 - val_loss: 19019808.1818 - val_mse: 19019810.0000\n",
      "Epoch 170/250\n",
      "616/616 [==============================] - 0s 50us/step - loss: 22384545.6169 - mse: 22384544.0000 - val_loss: 18956710.6494 - val_mse: 18956710.0000\n",
      "Epoch 171/250\n",
      "616/616 [==============================] - 0s 81us/step - loss: 22313927.2370 - mse: 22313926.0000 - val_loss: 18891536.8182 - val_mse: 18891536.0000\n",
      "Epoch 172/250\n",
      "616/616 [==============================] - 0s 97us/step - loss: 22243200.4416 - mse: 22243202.0000 - val_loss: 18825557.0519 - val_mse: 18825556.0000\n",
      "Epoch 173/250\n",
      "616/616 [==============================] - 0s 108us/step - loss: 22175278.4253 - mse: 22175278.0000 - val_loss: 18759947.5584 - val_mse: 18759948.0000\n",
      "Epoch 174/250\n",
      "616/616 [==============================] - 0s 75us/step - loss: 22101551.4286 - mse: 22101554.0000 - val_loss: 18695777.8442 - val_mse: 18695778.0000\n",
      "Epoch 175/250\n",
      "616/616 [==============================] - 0s 137us/step - loss: 22033834.9123 - mse: 22033834.0000 - val_loss: 18628982.9740 - val_mse: 18628984.0000\n",
      "Epoch 176/250\n",
      "616/616 [==============================] - 0s 184us/step - loss: 21961651.4286 - mse: 21961654.0000 - val_loss: 18561658.1818 - val_mse: 18561660.0000\n",
      "Epoch 177/250\n",
      "616/616 [==============================] - 0s 75us/step - loss: 21896300.7078 - mse: 21896298.0000 - val_loss: 18495915.5325 - val_mse: 18495916.0000\n",
      "Epoch 178/250\n",
      "616/616 [==============================] - 0s 74us/step - loss: 21826610.4156 - mse: 21826614.0000 - val_loss: 18430591.9610 - val_mse: 18430590.0000\n",
      "Epoch 179/250\n",
      "616/616 [==============================] - 0s 83us/step - loss: 21755945.9091 - mse: 21755946.0000 - val_loss: 18364924.2078 - val_mse: 18364924.0000\n",
      "Epoch 180/250\n",
      "616/616 [==============================] - 0s 69us/step - loss: 21687123.8961 - mse: 21687124.0000 - val_loss: 18297528.6104 - val_mse: 18297528.0000\n",
      "Epoch 181/250\n",
      "616/616 [==============================] - 0s 82us/step - loss: 21617601.6526 - mse: 21617600.0000 - val_loss: 18235467.3636 - val_mse: 18235466.0000\n",
      "Epoch 182/250\n",
      "616/616 [==============================] - 0s 84us/step - loss: 21551076.0584 - mse: 21551076.0000 - val_loss: 18176356.3636 - val_mse: 18176358.0000\n",
      "Epoch 183/250\n",
      "616/616 [==============================] - 0s 100us/step - loss: 21484822.9838 - mse: 21484824.0000 - val_loss: 18112538.9610 - val_mse: 18112536.0000\n",
      "Epoch 184/250\n",
      "616/616 [==============================] - 0s 89us/step - loss: 21414629.9351 - mse: 21414632.0000 - val_loss: 18049274.5974 - val_mse: 18049276.0000\n",
      "Epoch 185/250\n",
      "616/616 [==============================] - 0s 86us/step - loss: 21349584.9610 - mse: 21349582.0000 - val_loss: 17987057.0260 - val_mse: 17987058.0000\n",
      "Epoch 186/250\n",
      "616/616 [==============================] - 0s 73us/step - loss: 21282502.4545 - mse: 21282500.0000 - val_loss: 17922829.5195 - val_mse: 17922830.0000\n",
      "Epoch 187/250\n",
      "616/616 [==============================] - 0s 99us/step - loss: 21213729.0714 - mse: 21213730.0000 - val_loss: 17860058.3117 - val_mse: 17860058.0000\n",
      "Epoch 188/250\n",
      "616/616 [==============================] - 0s 100us/step - loss: 21151287.7045 - mse: 21151286.0000 - val_loss: 17795434.8831 - val_mse: 17795434.0000\n",
      "Epoch 189/250\n",
      "616/616 [==============================] - 0s 94us/step - loss: 21084615.3961 - mse: 21084618.0000 - val_loss: 17736765.5455 - val_mse: 17736766.0000\n",
      "Epoch 190/250\n",
      "616/616 [==============================] - 0s 102us/step - loss: 21017982.9578 - mse: 21017980.0000 - val_loss: 17679095.5065 - val_mse: 17679096.0000\n",
      "Epoch 191/250\n",
      "616/616 [==============================] - 0s 76us/step - loss: 20953620.1266 - mse: 20953620.0000 - val_loss: 17618681.1299 - val_mse: 17618682.0000\n",
      "Epoch 192/250\n",
      "616/616 [==============================] - 0s 93us/step - loss: 20890928.7208 - mse: 20890928.0000 - val_loss: 17559756.8701 - val_mse: 17559756.0000\n",
      "Epoch 193/250\n",
      "616/616 [==============================] - 0s 78us/step - loss: 20827284.0130 - mse: 20827286.0000 - val_loss: 17500008.2338 - val_mse: 17500008.0000\n",
      "Epoch 194/250\n",
      "616/616 [==============================] - 0s 72us/step - loss: 20762672.0065 - mse: 20762674.0000 - val_loss: 17443774.8052 - val_mse: 17443774.0000\n",
      "Epoch 195/250\n",
      "616/616 [==============================] - 0s 85us/step - loss: 20697425.9643 - mse: 20697426.0000 - val_loss: 17387135.4805 - val_mse: 17387136.0000\n",
      "Epoch 196/250\n",
      "616/616 [==============================] - 0s 82us/step - loss: 20635332.6364 - mse: 20635332.0000 - val_loss: 17333494.0649 - val_mse: 17333494.0000\n",
      "Epoch 197/250\n",
      "616/616 [==============================] - 0s 66us/step - loss: 20576601.4805 - mse: 20576604.0000 - val_loss: 17275846.8831 - val_mse: 17275848.0000\n",
      "Epoch 198/250\n",
      "616/616 [==============================] - 0s 61us/step - loss: 20512464.3636 - mse: 20512466.0000 - val_loss: 17217523.8442 - val_mse: 17217522.0000\n",
      "Epoch 199/250\n",
      "616/616 [==============================] - 0s 106us/step - loss: 20452231.2240 - mse: 20452232.0000 - val_loss: 17164330.6234 - val_mse: 17164332.0000\n",
      "Epoch 200/250\n",
      "616/616 [==============================] - 0s 80us/step - loss: 20390563.9870 - mse: 20390562.0000 - val_loss: 17108786.8571 - val_mse: 17108788.0000\n",
      "Epoch 201/250\n",
      "616/616 [==============================] - 0s 100us/step - loss: 20330759.1688 - mse: 20330758.0000 - val_loss: 17054493.0779 - val_mse: 17054494.0000\n",
      "Epoch 202/250\n",
      "616/616 [==============================] - 0s 90us/step - loss: 20273695.4545 - mse: 20273696.0000 - val_loss: 16997205.3377 - val_mse: 16997204.0000\n",
      "Epoch 203/250\n",
      "616/616 [==============================] - 0s 80us/step - loss: 20208593.2143 - mse: 20208594.0000 - val_loss: 16945546.9351 - val_mse: 16945548.0000\n",
      "Epoch 204/250\n",
      "616/616 [==============================] - 0s 95us/step - loss: 20150381.9383 - mse: 20150384.0000 - val_loss: 16891557.5584 - val_mse: 16891556.0000\n",
      "Epoch 205/250\n",
      "616/616 [==============================] - 0s 106us/step - loss: 20091956.5097 - mse: 20091956.0000 - val_loss: 16838463.5714 - val_mse: 16838464.0000\n",
      "Epoch 206/250\n",
      "616/616 [==============================] - 0s 123us/step - loss: 20033877.4675 - mse: 20033878.0000 - val_loss: 16785196.1948 - val_mse: 16785196.0000\n",
      "Epoch 207/250\n",
      "616/616 [==============================] - 0s 144us/step - loss: 19974763.9416 - mse: 19974764.0000 - val_loss: 16733995.1039 - val_mse: 16733995.0000\n",
      "Epoch 208/250\n",
      "616/616 [==============================] - 0s 164us/step - loss: 19917599.3539 - mse: 19917598.0000 - val_loss: 16684934.1558 - val_mse: 16684933.0000\n",
      "Epoch 209/250\n",
      "616/616 [==============================] - 0s 126us/step - loss: 19859213.9188 - mse: 19859214.0000 - val_loss: 16632541.3247 - val_mse: 16632541.0000\n",
      "Epoch 210/250\n",
      "616/616 [==============================] - 0s 136us/step - loss: 19803939.6981 - mse: 19803940.0000 - val_loss: 16583152.1169 - val_mse: 16583153.0000\n",
      "Epoch 211/250\n",
      "616/616 [==============================] - 0s 71us/step - loss: 19743780.0422 - mse: 19743780.0000 - val_loss: 16528768.5844 - val_mse: 16528768.0000\n",
      "Epoch 212/250\n",
      "616/616 [==============================] - 0s 63us/step - loss: 19686742.7338 - mse: 19686742.0000 - val_loss: 16475928.9610 - val_mse: 16475929.0000\n",
      "Epoch 213/250\n",
      "616/616 [==============================] - 0s 72us/step - loss: 19628956.9578 - mse: 19628956.0000 - val_loss: 16424931.5584 - val_mse: 16424932.0000\n",
      "Epoch 214/250\n",
      "616/616 [==============================] - 0s 131us/step - loss: 19572946.2143 - mse: 19572946.0000 - val_loss: 16375839.2857 - val_mse: 16375840.0000\n",
      "Epoch 215/250\n",
      "616/616 [==============================] - 0s 98us/step - loss: 19516517.6948 - mse: 19516516.0000 - val_loss: 16325973.5714 - val_mse: 16325973.0000\n",
      "Epoch 216/250\n",
      "616/616 [==============================] - 0s 88us/step - loss: 19461804.8019 - mse: 19461804.0000 - val_loss: 16274220.2078 - val_mse: 16274221.0000\n",
      "Epoch 217/250\n",
      "616/616 [==============================] - 0s 117us/step - loss: 19403577.1591 - mse: 19403576.0000 - val_loss: 16226126.8442 - val_mse: 16226128.0000\n",
      "Epoch 218/250\n",
      "616/616 [==============================] - 0s 89us/step - loss: 19352429.9708 - mse: 19352430.0000 - val_loss: 16175817.1688 - val_mse: 16175817.0000\n",
      "Epoch 219/250\n",
      "616/616 [==============================] - 0s 85us/step - loss: 19295494.1071 - mse: 19295492.0000 - val_loss: 16128267.1299 - val_mse: 16128268.0000\n",
      "Epoch 220/250\n",
      "616/616 [==============================] - 0s 92us/step - loss: 19240629.3864 - mse: 19240630.0000 - val_loss: 16081043.8961 - val_mse: 16081046.0000\n",
      "Epoch 221/250\n",
      "616/616 [==============================] - 0s 96us/step - loss: 19186880.2435 - mse: 19186880.0000 - val_loss: 16035832.0909 - val_mse: 16035833.0000\n",
      "Epoch 222/250\n",
      "616/616 [==============================] - 0s 82us/step - loss: 19135422.3734 - mse: 19135424.0000 - val_loss: 15989559.7143 - val_mse: 15989561.0000\n",
      "Epoch 223/250\n",
      "616/616 [==============================] - 0s 69us/step - loss: 19083500.5292 - mse: 19083502.0000 - val_loss: 15946747.8312 - val_mse: 15946749.0000\n",
      "Epoch 224/250\n",
      "616/616 [==============================] - 0s 94us/step - loss: 19037327.4091 - mse: 19037326.0000 - val_loss: 15904122.6234 - val_mse: 15904123.0000\n",
      "Epoch 225/250\n",
      "616/616 [==============================] - 0s 89us/step - loss: 18981685.8896 - mse: 18981686.0000 - val_loss: 15861413.1818 - val_mse: 15861413.0000\n",
      "Epoch 226/250\n",
      "616/616 [==============================] - 0s 82us/step - loss: 18933026.0779 - mse: 18933026.0000 - val_loss: 15815772.7662 - val_mse: 15815773.0000\n",
      "Epoch 227/250\n",
      "616/616 [==============================] - 0s 80us/step - loss: 18880944.8149 - mse: 18880946.0000 - val_loss: 15770306.1558 - val_mse: 15770306.0000\n",
      "Epoch 228/250\n",
      "616/616 [==============================] - 0s 75us/step - loss: 18830947.2987 - mse: 18830948.0000 - val_loss: 15726967.1169 - val_mse: 15726966.0000\n",
      "Epoch 229/250\n",
      "616/616 [==============================] - 0s 69us/step - loss: 18779252.8474 - mse: 18779250.0000 - val_loss: 15685477.9740 - val_mse: 15685479.0000\n",
      "Epoch 230/250\n",
      "616/616 [==============================] - 0s 93us/step - loss: 18731850.0227 - mse: 18731850.0000 - val_loss: 15639321.6104 - val_mse: 15639321.0000\n",
      "Epoch 231/250\n",
      "616/616 [==============================] - 0s 92us/step - loss: 18678570.1494 - mse: 18678572.0000 - val_loss: 15596918.8831 - val_mse: 15596920.0000\n",
      "Epoch 232/250\n",
      "616/616 [==============================] - 0s 102us/step - loss: 18630668.9935 - mse: 18630670.0000 - val_loss: 15552560.1169 - val_mse: 15552559.0000\n",
      "Epoch 233/250\n",
      "616/616 [==============================] - 0s 96us/step - loss: 18582567.9091 - mse: 18582566.0000 - val_loss: 15507955.9610 - val_mse: 15507955.0000\n",
      "Epoch 234/250\n",
      "616/616 [==============================] - 0s 96us/step - loss: 18530499.6721 - mse: 18530500.0000 - val_loss: 15468516.1818 - val_mse: 15468516.0000\n",
      "Epoch 235/250\n",
      "616/616 [==============================] - 0s 87us/step - loss: 18483847.6331 - mse: 18483848.0000 - val_loss: 15427580.9221 - val_mse: 15427581.0000\n",
      "Epoch 236/250\n",
      "616/616 [==============================] - 0s 105us/step - loss: 18437895.5584 - mse: 18437892.0000 - val_loss: 15385297.0260 - val_mse: 15385296.0000\n",
      "Epoch 237/250\n",
      "616/616 [==============================] - 0s 88us/step - loss: 18390041.0195 - mse: 18390040.0000 - val_loss: 15347655.5195 - val_mse: 15347655.0000\n",
      "Epoch 238/250\n",
      "616/616 [==============================] - 0s 104us/step - loss: 18344249.4740 - mse: 18344250.0000 - val_loss: 15308595.4026 - val_mse: 15308596.0000\n",
      "Epoch 239/250\n",
      "616/616 [==============================] - 0s 134us/step - loss: 18296880.4740 - mse: 18296882.0000 - val_loss: 15270521.2338 - val_mse: 15270521.0000\n",
      "Epoch 240/250\n",
      "616/616 [==============================] - 0s 89us/step - loss: 18252085.1201 - mse: 18252086.0000 - val_loss: 15232349.1948 - val_mse: 15232351.0000\n",
      "Epoch 241/250\n",
      "616/616 [==============================] - 0s 89us/step - loss: 18206179.7110 - mse: 18206180.0000 - val_loss: 15193293.1948 - val_mse: 15193294.0000\n",
      "Epoch 242/250\n",
      "616/616 [==============================] - 0s 65us/step - loss: 18161383.4870 - mse: 18161384.0000 - val_loss: 15154390.7143 - val_mse: 15154390.0000\n",
      "Epoch 243/250\n",
      "616/616 [==============================] - 0s 91us/step - loss: 18116383.1136 - mse: 18116382.0000 - val_loss: 15116230.5065 - val_mse: 15116230.0000\n",
      "Epoch 244/250\n",
      "616/616 [==============================] - 0s 85us/step - loss: 18072281.8701 - mse: 18072282.0000 - val_loss: 15079745.8442 - val_mse: 15079746.0000\n",
      "Epoch 245/250\n",
      "616/616 [==============================] - 0s 84us/step - loss: 18032256.1558 - mse: 18032256.0000 - val_loss: 15043784.5584 - val_mse: 15043785.0000\n",
      "Epoch 246/250\n",
      "616/616 [==============================] - 0s 73us/step - loss: 17983367.7532 - mse: 17983370.0000 - val_loss: 15007185.4935 - val_mse: 15007185.0000\n",
      "Epoch 247/250\n",
      "616/616 [==============================] - 0s 80us/step - loss: 17940669.2240 - mse: 17940670.0000 - val_loss: 14970622.4935 - val_mse: 14970622.0000\n",
      "Epoch 248/250\n",
      "616/616 [==============================] - 0s 80us/step - loss: 17895471.9838 - mse: 17895470.0000 - val_loss: 14933903.1299 - val_mse: 14933905.0000\n",
      "Epoch 249/250\n",
      "616/616 [==============================] - 0s 111us/step - loss: 17854328.4156 - mse: 17854328.0000 - val_loss: 14898688.6364 - val_mse: 14898688.0000\n",
      "Epoch 250/250\n",
      "616/616 [==============================] - 0s 71us/step - loss: 17811887.2565 - mse: 17811886.0000 - val_loss: 14865050.5065 - val_mse: 14865051.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain, ytrain, epochs=250, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mse', 'loss', 'mse'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value=model.predict(xtest)\n",
    "predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value=predicted_value.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({'Actual':ytest,'Predicted':predicted_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10747</td>\n",
       "      <td>7182.376465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9913</td>\n",
       "      <td>14381.114258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3328</td>\n",
       "      <td>7627.970215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5580</td>\n",
       "      <td>6242.274902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15541</td>\n",
       "      <td>14981.354492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual     Predicted\n",
       "0   10747   7182.376465\n",
       "1    9913  14381.114258\n",
       "2    3328   7627.970215\n",
       "3    5580   6242.274902\n",
       "4   15541  14981.354492"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the new Data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[3.20e+01 1.00e+00 5.40e+01 3.51e+04 7.14e+03], Predicted=[19871.135]\n"
     ]
    }
   ],
   "source": [
    "xnew = np.array([[32, 1, 54, 35100, 7140]])\n",
    "xnew= scaler.transform(xnew)\n",
    "ynew= model.predict(xnew)\n",
    "#invert normalize\n",
    "#ynew = scaler_y.inverse_transform(ynew) \n",
    "xnew1 = scaler.inverse_transform(xnew)\n",
    "print(\"X=%s, Predicted=%s\" % (xnew1[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>miles</th>\n",
       "      <th>debt</th>\n",
       "      <th>income</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4099</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2677</td>\n",
       "      <td>1792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>41576</td>\n",
       "      <td>6215</td>\n",
       "      <td>27754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>43172</td>\n",
       "      <td>7626</td>\n",
       "      <td>28256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6979</td>\n",
       "      <td>8071</td>\n",
       "      <td>4438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3205</td>\n",
       "      <td>6823</td>\n",
       "      <td>5332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>946</td>\n",
       "      <td>1059</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8778</td>\n",
       "      <td>9829</td>\n",
       "      <td>1593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4850</td>\n",
       "      <td>3470</td>\n",
       "      <td>4742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>9312</td>\n",
       "      <td>2720</td>\n",
       "      <td>12771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  miles   debt  income  sales\n",
       "0     28       0     23      0    4099    620\n",
       "1     26       0     27      0    2677   1792\n",
       "2     30       1     58  41576    6215  27754\n",
       "3     26       1     25  43172    7626  28256\n",
       "4     20       1     17   6979    8071   4438\n",
       "..   ...     ...    ...    ...     ...    ...\n",
       "946   25       1     10   3205    6823   5332\n",
       "951   24       1     26    946    1059   2509\n",
       "958   22       0     11   8778    9829   1593\n",
       "959   19       1     23   4850    3470   4742\n",
       "960   28       1     28   9312    2720  12771\n",
       "\n",
       "[440 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.age<=35]\n",
    "2\t30\t1\t58\t41576\t6215\t27754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
